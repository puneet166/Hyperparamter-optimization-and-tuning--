{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-8oPtXzW_gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0be4c249-97d7-4968-f4e2-bc7f2eebd6ba"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "da=pd.read_csv('FileName.csv')\n",
        "da"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
              "0           0       3    1  22.0      1      0   7.2500         2\n",
              "1           1       1    0  38.0      1      0  71.2833         0\n",
              "2           1       3    0  26.0      0      0   7.9250         2\n",
              "3           1       1    0  35.0      1      0  53.1000         2\n",
              "4           0       3    1  35.0      0      0   8.0500         2\n",
              "..        ...     ...  ...   ...    ...    ...      ...       ...\n",
              "886         0       2    1  27.0      0      0  13.0000         2\n",
              "887         1       1    0  19.0      0      0  30.0000         2\n",
              "888         0       3    0  30.0      1      2  23.4500         2\n",
              "889         1       1    1  26.0      0      0  30.0000         0\n",
              "890         0       3    1  32.0      0      0   7.7500         1\n",
              "\n",
              "[891 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWkBZMzWRvtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#da=da.drop(['SibSp','Parch'],axis=1)\n",
        "#da\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxqhppocSsM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "94a903c4-f5a3-47de-dc6e-d6e81c463715"
      },
      "source": [
        "da"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
              "0           0       3    1  22.0      1      0   7.2500         2\n",
              "1           1       1    0  38.0      1      0  71.2833         0\n",
              "2           1       3    0  26.0      0      0   7.9250         2\n",
              "3           1       1    0  35.0      1      0  53.1000         2\n",
              "4           0       3    1  35.0      0      0   8.0500         2\n",
              "..        ...     ...  ...   ...    ...    ...      ...       ...\n",
              "886         0       2    1  27.0      0      0  13.0000         2\n",
              "887         1       1    0  19.0      0      0  30.0000         2\n",
              "888         0       3    0  30.0      1      2  23.4500         2\n",
              "889         1       1    1  26.0      0      0  30.0000         0\n",
              "890         0       3    1  32.0      0      0   7.7500         1\n",
              "\n",
              "[891 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNGBatRUebSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avz7IHf3UY7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "82b2a90e-2c89-420f-9852-9a1815db421b"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "da[['Age','Fare']]=scaler.fit_transform(da[['Age','Fare']].values)\n",
        "da"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.103644</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.025374</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.371701</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.045771</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015127</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
              "0           0       3    1  0.271174      1      0  0.014151         2\n",
              "1           1       1    0  0.472229      1      0  0.139136         0\n",
              "2           1       3    0  0.321438      0      0  0.015469         2\n",
              "3           1       1    0  0.434531      1      0  0.103644         2\n",
              "4           0       3    1  0.434531      0      0  0.015713         2\n",
              "..        ...     ...  ...       ...    ...    ...       ...       ...\n",
              "886         0       2    1  0.334004      0      0  0.025374         2\n",
              "887         1       1    0  0.233476      0      0  0.058556         2\n",
              "888         0       3    0  0.371701      1      2  0.045771         2\n",
              "889         1       1    1  0.321438      0      0  0.058556         0\n",
              "890         0       3    1  0.396833      0      0  0.015127         1\n",
              "\n",
              "[891 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIgK8jLZYHjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x=da['Survived']\n",
        "\n",
        "y=da.iloc[:,1:8]"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_avu8-oLYMZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8b6f360e-8491-4309-e412-965bb184112c"
      },
      "source": [
        "y"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.103644</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.025374</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.371701</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.045771</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015127</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
              "0         3    1  0.271174      1      0  0.014151         2\n",
              "1         1    0  0.472229      1      0  0.139136         0\n",
              "2         3    0  0.321438      0      0  0.015469         2\n",
              "3         1    0  0.434531      1      0  0.103644         2\n",
              "4         3    1  0.434531      0      0  0.015713         2\n",
              "..      ...  ...       ...    ...    ...       ...       ...\n",
              "886       2    1  0.334004      0      0  0.025374         2\n",
              "887       1    0  0.233476      0      0  0.058556         2\n",
              "888       3    0  0.371701      1      2  0.045771         2\n",
              "889       1    1  0.321438      0      0  0.058556         0\n",
              "890       3    1  0.396833      0      0  0.015127         1\n",
              "\n",
              "[891 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwfgXvl3Yg-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential # its for create ANN algorithm\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU,PReLU,ELU # its for relu activations function \n"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YW9VhboZa6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGQr89rkZlEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "#model.add(tf.keras.Input(shape=(7,)))\n",
        "model.add(Dense(440, input_dim=7, activation='relu'))\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZyJIcncZnKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(440,activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "opt=keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcKqAWt0ey3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f1ad20ff-82cf-41bf-945d-4b22e832004e"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 440)               3520      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 440)               194040    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 441       \n",
            "=================================================================\n",
            "Total params: 198,001\n",
            "Trainable params: 198,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQChjKxIe-Zq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "e255afbd-b7a5-415a-93ee-dbbe96133bcd"
      },
      "source": [
        "history=model.fit(y, x,epochs=20, batch_size=5, verbose=1) \n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4556 - accuracy: 0.8013\n",
            "Epoch 2/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4550 - accuracy: 0.8114\n",
            "Epoch 3/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4440 - accuracy: 0.8002\n",
            "Epoch 4/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.8070\n",
            "Epoch 5/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4432 - accuracy: 0.8058\n",
            "Epoch 6/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4501 - accuracy: 0.8103\n",
            "Epoch 7/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.8081\n",
            "Epoch 8/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4500 - accuracy: 0.8114\n",
            "Epoch 9/20\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.4383 - accuracy: 0.8058\n",
            "Epoch 10/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4486 - accuracy: 0.8047\n",
            "Epoch 11/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4290 - accuracy: 0.8171\n",
            "Epoch 12/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4270 - accuracy: 0.8193\n",
            "Epoch 13/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4354 - accuracy: 0.8182\n",
            "Epoch 14/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4182 - accuracy: 0.8249\n",
            "Epoch 15/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4275 - accuracy: 0.8249\n",
            "Epoch 16/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4308 - accuracy: 0.8238\n",
            "Epoch 17/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4336 - accuracy: 0.8215\n",
            "Epoch 18/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4275 - accuracy: 0.8227\n",
            "Epoch 19/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4152 - accuracy: 0.8294\n",
            "Epoch 20/20\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4287 - accuracy: 0.8148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZAxWgjAfK-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "49b7d63f-aadb-45cf-d8d8-90bd18a3bc43"
      },
      "source": [
        "pip install -U keras-tuner\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras-tuner in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_g_KgXahuZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmTZnEkSh0W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kerastuner.tuners import RandomSearch\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEljlJ7Ih4E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Dense(units=hp.Int('units',\n",
        "                                        min_value=16,\n",
        "                                        max_value=512,\n",
        "                                        step=8),\n",
        "                           activation=hp.Choice(\n",
        "        'dense_activation',\n",
        "        values=['relu', 'tanh', 'sigmoid'],\n",
        "        default='relu'\n",
        "    )))\n",
        "    model.add(Dense(units=hp.Int('units',\n",
        "                                        min_value=8,\n",
        "                                        max_value=512,\n",
        "                                        step=8),\n",
        "                           activation=hp.Choice(\n",
        "        'dense_activation',\n",
        "        values=['relu', 'tanh', 'sigmoid'],\n",
        "        default='relu'\n",
        "    )))\n",
        "    \n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate',\n",
        "                      values=[1e-2, 1e-3, 1e-4])),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcnlyXEYiawI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dggluir',\n",
        "    project_name='helloworld')"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6ZQxKCyiiUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "09f87983-41da-499e-be6c-56f3a34fb997"
      },
      "source": [
        "tuner.search_space_summary()\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Default search space size: 3</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-max_value: 512</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-min_value: 16</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-sampling: None</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-step: 8</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">dense_activation (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: relu</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: False</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: ['relu', 'tanh', 'sigmoid']</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-default: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-ordered: True</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kszSwwcdjjZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab3c036d-1378-4e62-92f2-5d8da08462a5"
      },
      "source": [
        "tuner.search(y, x,validation_split=0.01,epochs=20, batch_size=5, verbose=1)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 1s 3ms/step - loss: 0.6007 - accuracy: 0.6497 - val_loss: 0.6868 - val_accuracy: 0.5556\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7766 - val_loss: 0.7899 - val_accuracy: 0.5556\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7823 - val_loss: 0.7229 - val_accuracy: 0.5556\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7880 - val_loss: 0.7108 - val_accuracy: 0.5556\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7902 - val_loss: 0.7768 - val_accuracy: 0.5556\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7959 - val_loss: 0.6122 - val_accuracy: 0.5556\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7982 - val_loss: 0.6456 - val_accuracy: 0.5556\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7925 - val_loss: 0.6018 - val_accuracy: 0.5556\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8016 - val_loss: 0.8929 - val_accuracy: 0.5556\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7948 - val_loss: 0.6564 - val_accuracy: 0.5556\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8016 - val_loss: 0.6239 - val_accuracy: 0.5556\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7880 - val_loss: 0.6265 - val_accuracy: 0.5556\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7982 - val_loss: 0.4756 - val_accuracy: 0.7778\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7993 - val_loss: 0.5143 - val_accuracy: 0.5556\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7971 - val_loss: 0.5821 - val_accuracy: 0.5556\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7993 - val_loss: 0.4549 - val_accuracy: 0.7778\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7971 - val_loss: 0.6664 - val_accuracy: 0.5556\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8005 - val_loss: 0.6447 - val_accuracy: 0.5556\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8039 - val_loss: 0.5055 - val_accuracy: 0.5556\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8050 - val_loss: 0.5618 - val_accuracy: 0.5556\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.6735 - val_loss: 0.6401 - val_accuracy: 0.5556\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7483 - val_loss: 0.7032 - val_accuracy: 0.5556\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7868 - val_loss: 0.6886 - val_accuracy: 0.5556\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7925 - val_loss: 0.7076 - val_accuracy: 0.5556\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7868 - val_loss: 0.8352 - val_accuracy: 0.5556\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7959 - val_loss: 0.6452 - val_accuracy: 0.5556\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7993 - val_loss: 0.7667 - val_accuracy: 0.5556\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7982 - val_loss: 0.5075 - val_accuracy: 0.5556\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7982 - val_loss: 0.6627 - val_accuracy: 0.5556\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7925 - val_loss: 0.5883 - val_accuracy: 0.5556\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7948 - val_loss: 0.6293 - val_accuracy: 0.5556\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7948 - val_loss: 0.4554 - val_accuracy: 0.7778\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7982 - val_loss: 0.5472 - val_accuracy: 0.5556\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7982 - val_loss: 0.6140 - val_accuracy: 0.5556\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7959 - val_loss: 0.5429 - val_accuracy: 0.5556\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7993 - val_loss: 0.6059 - val_accuracy: 0.5556\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7993 - val_loss: 0.5592 - val_accuracy: 0.5556\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7959 - val_loss: 0.4790 - val_accuracy: 0.5556\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8039 - val_loss: 0.6182 - val_accuracy: 0.5556\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7993 - val_loss: 0.6053 - val_accuracy: 0.5556\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6338 - val_loss: 0.7395 - val_accuracy: 0.6667\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7517 - val_loss: 0.7409 - val_accuracy: 0.5556\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7891 - val_loss: 0.7804 - val_accuracy: 0.5556\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7902 - val_loss: 0.6469 - val_accuracy: 0.5556\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8005 - val_loss: 0.6846 - val_accuracy: 0.5556\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7959 - val_loss: 0.7117 - val_accuracy: 0.5556\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7959 - val_loss: 0.7207 - val_accuracy: 0.5556\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7959 - val_loss: 0.6721 - val_accuracy: 0.5556\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7948 - val_loss: 0.5802 - val_accuracy: 0.5556\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8039 - val_loss: 0.5778 - val_accuracy: 0.5556\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7982 - val_loss: 0.5151 - val_accuracy: 0.5556\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7959 - val_loss: 0.5983 - val_accuracy: 0.5556\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7971 - val_loss: 0.6273 - val_accuracy: 0.5556\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7982 - val_loss: 0.5259 - val_accuracy: 0.5556\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7914 - val_loss: 0.6198 - val_accuracy: 0.5556\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7982 - val_loss: 0.4621 - val_accuracy: 0.7778\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7993 - val_loss: 0.5150 - val_accuracy: 0.6667\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7993 - val_loss: 0.5310 - val_accuracy: 0.5556\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7993 - val_loss: 0.5065 - val_accuracy: 0.6667\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8027 - val_loss: 0.5224 - val_accuracy: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 2b4a3fb951da6c4d649380f9297f28bc</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.7777777910232544</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: tanh</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 272</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6145 - val_loss: 0.4912 - val_accuracy: 0.7778\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.6126 - accuracy: 0.6145 - val_loss: 0.4932 - val_accuracy: 0.7778\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6168 - val_loss: 0.4989 - val_accuracy: 0.7778\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6304 - val_loss: 0.5019 - val_accuracy: 0.7778\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6644 - val_loss: 0.5049 - val_accuracy: 0.7778\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.6950 - val_loss: 0.5112 - val_accuracy: 0.7778\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7188 - val_loss: 0.5260 - val_accuracy: 0.7778\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7415 - val_loss: 0.5220 - val_accuracy: 0.7778\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7472 - val_loss: 0.5292 - val_accuracy: 0.7778\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7540 - val_loss: 0.5362 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7585 - val_loss: 0.5462 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7698 - val_loss: 0.5506 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7914 - val_loss: 0.5632 - val_accuracy: 0.6667\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8016 - val_loss: 0.5650 - val_accuracy: 0.6667\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8084 - val_loss: 0.5664 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8107 - val_loss: 0.5619 - val_accuracy: 0.6667\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8073 - val_loss: 0.5633 - val_accuracy: 0.5556\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8050 - val_loss: 0.5639 - val_accuracy: 0.5556\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8073 - val_loss: 0.5659 - val_accuracy: 0.5556\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8073 - val_loss: 0.5615 - val_accuracy: 0.5556\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6259 - val_loss: 0.5619 - val_accuracy: 0.6667\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6315 - val_loss: 0.5334 - val_accuracy: 0.7778\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.6395 - val_loss: 0.5295 - val_accuracy: 0.7778\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6633 - val_loss: 0.5271 - val_accuracy: 0.7778\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6927 - val_loss: 0.5304 - val_accuracy: 0.7778\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7313 - val_loss: 0.5348 - val_accuracy: 0.6667\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7336 - val_loss: 0.5445 - val_accuracy: 0.6667\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7472 - val_loss: 0.5434 - val_accuracy: 0.6667\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.7574 - val_loss: 0.5543 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7710 - val_loss: 0.5697 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7698 - val_loss: 0.5678 - val_accuracy: 0.5556\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7710 - val_loss: 0.5992 - val_accuracy: 0.5556\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7914 - val_loss: 0.5712 - val_accuracy: 0.5556\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7925 - val_loss: 0.5799 - val_accuracy: 0.5556\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7914 - val_loss: 0.5543 - val_accuracy: 0.5556\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7948 - val_loss: 0.5435 - val_accuracy: 0.5556\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8005 - val_loss: 0.5544 - val_accuracy: 0.5556\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.8039 - val_loss: 0.5802 - val_accuracy: 0.5556\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8005 - val_loss: 0.5587 - val_accuracy: 0.5556\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.8027 - val_loss: 0.5822 - val_accuracy: 0.5556\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.6100 - val_loss: 0.5195 - val_accuracy: 0.7778\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6145 - val_loss: 0.4970 - val_accuracy: 0.7778\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6145 - val_loss: 0.4854 - val_accuracy: 0.7778\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.6199 - accuracy: 0.6156 - val_loss: 0.4855 - val_accuracy: 0.7778\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6202 - val_loss: 0.4856 - val_accuracy: 0.7778\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6247 - val_loss: 0.4863 - val_accuracy: 0.7778\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6349 - val_loss: 0.4941 - val_accuracy: 0.8889\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.6599 - val_loss: 0.4944 - val_accuracy: 0.8889\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.7075 - val_loss: 0.5000 - val_accuracy: 0.8889\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7460 - val_loss: 0.5055 - val_accuracy: 0.7778\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7540 - val_loss: 0.5163 - val_accuracy: 0.7778\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7687 - val_loss: 0.5165 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7766 - val_loss: 0.5336 - val_accuracy: 0.6667\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7868 - val_loss: 0.5349 - val_accuracy: 0.6667\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8016 - val_loss: 0.5373 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7948 - val_loss: 0.5472 - val_accuracy: 0.5556\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8073 - val_loss: 0.5430 - val_accuracy: 0.5556\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8084 - val_loss: 0.5438 - val_accuracy: 0.5556\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.8095 - val_loss: 0.5450 - val_accuracy: 0.5556\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.8084 - val_loss: 0.5544 - val_accuracy: 0.5556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: f12c3f5635137afeb4e6291da29a18cd</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.814814825852712</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 40</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.8564 - accuracy: 0.5431 - val_loss: 0.8278 - val_accuracy: 0.2222\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.6303 - accuracy: 0.6587 - val_loss: 0.6502 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4705 - accuracy: 0.8005 - val_loss: 0.4160 - val_accuracy: 0.7778\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5039 - accuracy: 0.7846 - val_loss: 0.4228 - val_accuracy: 0.6667\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4679 - accuracy: 0.7959 - val_loss: 0.3923 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4658 - accuracy: 0.7959 - val_loss: 0.3163 - val_accuracy: 0.8889\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4544 - accuracy: 0.7778 - val_loss: 0.4740 - val_accuracy: 0.6667\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4439 - accuracy: 0.8016 - val_loss: 0.5859 - val_accuracy: 0.5556\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.7982 - val_loss: 0.3244 - val_accuracy: 0.8889\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4613 - accuracy: 0.7868 - val_loss: 0.3619 - val_accuracy: 0.7778\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4436 - accuracy: 0.8073 - val_loss: 0.4764 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.8050 - val_loss: 0.5525 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4436 - accuracy: 0.8005 - val_loss: 0.3418 - val_accuracy: 0.8889\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.8073 - val_loss: 0.4339 - val_accuracy: 0.7778\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4378 - accuracy: 0.8163 - val_loss: 0.2923 - val_accuracy: 0.8889\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4400 - accuracy: 0.8073 - val_loss: 0.4167 - val_accuracy: 0.7778\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4320 - accuracy: 0.8141 - val_loss: 0.4583 - val_accuracy: 0.7778\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4342 - accuracy: 0.8311 - val_loss: 0.2954 - val_accuracy: 0.8889\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4360 - accuracy: 0.8163 - val_loss: 0.2918 - val_accuracy: 0.8889\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4222 - accuracy: 0.8254 - val_loss: 0.3833 - val_accuracy: 0.7778\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.7684 - accuracy: 0.5850 - val_loss: 0.4918 - val_accuracy: 0.7778\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5265 - accuracy: 0.7642 - val_loss: 0.4203 - val_accuracy: 0.8889\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.7971 - val_loss: 0.3463 - val_accuracy: 0.8889\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4820 - accuracy: 0.7766 - val_loss: 0.4262 - val_accuracy: 0.7778\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4701 - accuracy: 0.8039 - val_loss: 0.4677 - val_accuracy: 0.5556\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4575 - accuracy: 0.7891 - val_loss: 0.6583 - val_accuracy: 0.6667\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4674 - accuracy: 0.7937 - val_loss: 0.5694 - val_accuracy: 0.5556\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4451 - accuracy: 0.8005 - val_loss: 0.3332 - val_accuracy: 0.8889\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4512 - accuracy: 0.8005 - val_loss: 0.3476 - val_accuracy: 0.8889\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4619 - accuracy: 0.8016 - val_loss: 0.4825 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4457 - accuracy: 0.7937 - val_loss: 0.3640 - val_accuracy: 0.8889\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4496 - accuracy: 0.8050 - val_loss: 0.3849 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4466 - accuracy: 0.7959 - val_loss: 0.3311 - val_accuracy: 0.7778\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4442 - accuracy: 0.8107 - val_loss: 0.3721 - val_accuracy: 0.8889\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4347 - accuracy: 0.8095 - val_loss: 0.6401 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4323 - accuracy: 0.8265 - val_loss: 0.4025 - val_accuracy: 0.7778\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4239 - accuracy: 0.8197 - val_loss: 0.3694 - val_accuracy: 0.7778\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4148 - accuracy: 0.8288 - val_loss: 0.2804 - val_accuracy: 0.8889\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4272 - accuracy: 0.8254 - val_loss: 0.3402 - val_accuracy: 0.7778\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4175 - accuracy: 0.8129 - val_loss: 0.5337 - val_accuracy: 0.6667\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.7400 - accuracy: 0.6259 - val_loss: 0.5159 - val_accuracy: 0.7778\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5279 - accuracy: 0.7642 - val_loss: 0.4639 - val_accuracy: 0.7778\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5021 - accuracy: 0.7823 - val_loss: 0.3132 - val_accuracy: 0.8889\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4824 - accuracy: 0.8061 - val_loss: 0.5837 - val_accuracy: 0.6667\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4743 - accuracy: 0.7914 - val_loss: 0.6577 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4654 - accuracy: 0.7948 - val_loss: 0.9395 - val_accuracy: 0.5556\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4689 - accuracy: 0.7925 - val_loss: 0.3001 - val_accuracy: 0.8889\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4898 - accuracy: 0.7971 - val_loss: 0.3267 - val_accuracy: 0.8889\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4572 - accuracy: 0.7823 - val_loss: 0.4281 - val_accuracy: 0.5556\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4228 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4589 - accuracy: 0.7891 - val_loss: 0.8734 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4457 - accuracy: 0.7993 - val_loss: 0.2642 - val_accuracy: 0.8889\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4570 - accuracy: 0.7948 - val_loss: 0.4466 - val_accuracy: 0.6667\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4357 - accuracy: 0.8095 - val_loss: 0.3640 - val_accuracy: 0.7778\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4507 - accuracy: 0.7948 - val_loss: 0.3594 - val_accuracy: 0.7778\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.8220 - val_loss: 0.2559 - val_accuracy: 0.8889\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4391 - accuracy: 0.7971 - val_loss: 0.3216 - val_accuracy: 0.7778\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4484 - accuracy: 0.8175 - val_loss: 0.4370 - val_accuracy: 0.6667\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.8061 - val_loss: 0.4940 - val_accuracy: 0.5556\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.8163 - val_loss: 0.3258 - val_accuracy: 0.7778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e3437a02e9d5b988bd2e16fd638e34cb</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.9259259303410848</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: sigmoid</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 440</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5834 - accuracy: 0.7370 - val_loss: 0.7359 - val_accuracy: 0.5556\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5027 - accuracy: 0.7721 - val_loss: 0.5794 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4778 - accuracy: 0.7891 - val_loss: 0.4587 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4785 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.5556\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4729 - accuracy: 0.7846 - val_loss: 0.6009 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4632 - accuracy: 0.8005 - val_loss: 0.4509 - val_accuracy: 0.6667\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4591 - accuracy: 0.7925 - val_loss: 0.5173 - val_accuracy: 0.6667\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4568 - accuracy: 0.8016 - val_loss: 0.4283 - val_accuracy: 0.7778\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4547 - accuracy: 0.8073 - val_loss: 0.6063 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4494 - accuracy: 0.8061 - val_loss: 0.6065 - val_accuracy: 0.5556\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4533 - accuracy: 0.8039 - val_loss: 0.6318 - val_accuracy: 0.5556\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4633 - accuracy: 0.7891 - val_loss: 0.4415 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4411 - accuracy: 0.8039 - val_loss: 0.3672 - val_accuracy: 0.8889\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4508 - accuracy: 0.7993 - val_loss: 0.4575 - val_accuracy: 0.7778\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4535 - accuracy: 0.8061 - val_loss: 0.4021 - val_accuracy: 0.7778\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4388 - accuracy: 0.8073 - val_loss: 0.4449 - val_accuracy: 0.5556\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4462 - accuracy: 0.7902 - val_loss: 0.5413 - val_accuracy: 0.5556\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4423 - accuracy: 0.8152 - val_loss: 0.3729 - val_accuracy: 0.7778\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4352 - accuracy: 0.8107 - val_loss: 0.3984 - val_accuracy: 0.7778\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4321 - accuracy: 0.8231 - val_loss: 0.4026 - val_accuracy: 0.7778\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5936 - accuracy: 0.7313 - val_loss: 0.4553 - val_accuracy: 0.7778\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4998 - accuracy: 0.7846 - val_loss: 0.3852 - val_accuracy: 0.8889\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4760 - accuracy: 0.7993 - val_loss: 0.5265 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.3947 - val_accuracy: 0.7778\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4729 - accuracy: 0.7891 - val_loss: 0.3932 - val_accuracy: 0.7778\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4628 - accuracy: 0.7959 - val_loss: 0.3776 - val_accuracy: 0.7778\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4592 - accuracy: 0.7971 - val_loss: 0.3518 - val_accuracy: 0.7778\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4604 - accuracy: 0.8027 - val_loss: 0.4522 - val_accuracy: 0.7778\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4620 - accuracy: 0.8027 - val_loss: 0.4066 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4615 - accuracy: 0.7971 - val_loss: 0.4303 - val_accuracy: 0.7778\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4494 - accuracy: 0.8039 - val_loss: 0.5000 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.8005 - val_loss: 0.6176 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.8039 - val_loss: 0.4410 - val_accuracy: 0.6667\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4451 - accuracy: 0.8175 - val_loss: 0.3855 - val_accuracy: 0.7778\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4453 - accuracy: 0.7925 - val_loss: 0.3556 - val_accuracy: 0.7778\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4509 - accuracy: 0.8152 - val_loss: 0.3642 - val_accuracy: 0.7778\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4499 - accuracy: 0.8152 - val_loss: 0.5176 - val_accuracy: 0.6667\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4380 - accuracy: 0.8050 - val_loss: 0.4821 - val_accuracy: 0.7778\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4374 - accuracy: 0.8084 - val_loss: 0.3816 - val_accuracy: 0.8889\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4441 - accuracy: 0.8095 - val_loss: 0.3349 - val_accuracy: 0.7778\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.5585 - accuracy: 0.7460 - val_loss: 0.3756 - val_accuracy: 0.8889\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4882 - accuracy: 0.7834 - val_loss: 0.8491 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.5014 - accuracy: 0.7755 - val_loss: 0.4300 - val_accuracy: 0.7778\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4715 - accuracy: 0.7925 - val_loss: 0.3710 - val_accuracy: 0.8889\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4710 - accuracy: 0.7937 - val_loss: 0.4011 - val_accuracy: 0.7778\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4615 - accuracy: 0.7971 - val_loss: 0.6221 - val_accuracy: 0.5556\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4655 - accuracy: 0.8016 - val_loss: 0.4693 - val_accuracy: 0.6667\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4618 - accuracy: 0.8027 - val_loss: 0.6367 - val_accuracy: 0.5556\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4611 - accuracy: 0.7971 - val_loss: 0.5315 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.8050 - val_loss: 0.4507 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4457 - accuracy: 0.8050 - val_loss: 0.5607 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4583 - accuracy: 0.7993 - val_loss: 0.4098 - val_accuracy: 0.7778\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4494 - accuracy: 0.7914 - val_loss: 0.4475 - val_accuracy: 0.7778\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4505 - accuracy: 0.7959 - val_loss: 0.4301 - val_accuracy: 0.7778\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4440 - accuracy: 0.8084 - val_loss: 0.4834 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4466 - accuracy: 0.8005 - val_loss: 0.3398 - val_accuracy: 0.7778\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4418 - accuracy: 0.8061 - val_loss: 0.4257 - val_accuracy: 0.7778\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4373 - accuracy: 0.8073 - val_loss: 0.4280 - val_accuracy: 0.7778\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4407 - accuracy: 0.8084 - val_loss: 0.3810 - val_accuracy: 0.8889\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 1s 4ms/step - loss: 0.4354 - accuracy: 0.8209 - val_loss: 0.3982 - val_accuracy: 0.7778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e976db2092b066d741c61f6b5a6de039</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.8888888955116272</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: tanh</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 448</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7256 - val_loss: 0.7463 - val_accuracy: 0.5556\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7971 - val_loss: 0.4937 - val_accuracy: 0.5556\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8027 - val_loss: 0.4442 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7993 - val_loss: 0.5591 - val_accuracy: 0.6667\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8129 - val_loss: 0.4654 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8061 - val_loss: 0.4292 - val_accuracy: 0.7778\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8175 - val_loss: 0.3619 - val_accuracy: 0.7778\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8107 - val_loss: 0.3794 - val_accuracy: 0.7778\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8163 - val_loss: 0.5026 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8084 - val_loss: 0.4427 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8311 - val_loss: 0.4084 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8243 - val_loss: 0.3891 - val_accuracy: 0.8889\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8265 - val_loss: 0.5338 - val_accuracy: 0.6667\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8322 - val_loss: 0.4087 - val_accuracy: 0.6667\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8333 - val_loss: 0.4153 - val_accuracy: 0.7778\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8356 - val_loss: 0.4952 - val_accuracy: 0.6667\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8311 - val_loss: 0.4666 - val_accuracy: 0.6667\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8322 - val_loss: 0.4069 - val_accuracy: 0.8889\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8379 - val_loss: 0.3173 - val_accuracy: 0.8889\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8345 - val_loss: 0.3784 - val_accuracy: 0.7778\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7211 - val_loss: 0.4826 - val_accuracy: 0.6667\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7948 - val_loss: 0.4601 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8095 - val_loss: 0.4388 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8073 - val_loss: 0.5436 - val_accuracy: 0.6667\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8107 - val_loss: 0.4020 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8141 - val_loss: 0.4375 - val_accuracy: 0.6667\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8129 - val_loss: 0.3397 - val_accuracy: 0.8889\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8152 - val_loss: 0.5125 - val_accuracy: 0.6667\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8163 - val_loss: 0.4345 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8197 - val_loss: 0.6136 - val_accuracy: 0.5556\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8288 - val_loss: 0.4348 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8322 - val_loss: 0.3108 - val_accuracy: 0.8889\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8243 - val_loss: 0.3997 - val_accuracy: 0.7778\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8311 - val_loss: 0.4157 - val_accuracy: 0.7778\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8231 - val_loss: 0.4036 - val_accuracy: 0.7778\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8220 - val_loss: 0.3505 - val_accuracy: 0.7778\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8379 - val_loss: 0.3563 - val_accuracy: 0.7778\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8163 - val_loss: 0.3655 - val_accuracy: 0.7778\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8379 - val_loss: 0.3911 - val_accuracy: 0.8889\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8345 - val_loss: 0.3064 - val_accuracy: 0.7778\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7381 - val_loss: 0.7902 - val_accuracy: 0.5556\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7959 - val_loss: 0.5304 - val_accuracy: 0.5556\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8016 - val_loss: 0.5504 - val_accuracy: 0.5556\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7914 - val_loss: 0.5740 - val_accuracy: 0.5556\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8073 - val_loss: 0.4771 - val_accuracy: 0.5556\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8141 - val_loss: 0.5466 - val_accuracy: 0.5556\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8118 - val_loss: 0.4363 - val_accuracy: 0.7778\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8095 - val_loss: 0.3786 - val_accuracy: 0.8889\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8197 - val_loss: 0.3506 - val_accuracy: 0.8889\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8129 - val_loss: 0.4559 - val_accuracy: 0.7778\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8311 - val_loss: 0.3602 - val_accuracy: 0.7778\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8163 - val_loss: 0.3771 - val_accuracy: 0.8889\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8209 - val_loss: 0.3467 - val_accuracy: 0.8889\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8243 - val_loss: 0.4276 - val_accuracy: 0.7778\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8152 - val_loss: 0.3789 - val_accuracy: 0.8889\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8265 - val_loss: 0.3448 - val_accuracy: 0.8889\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8288 - val_loss: 0.3936 - val_accuracy: 0.7778\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8322 - val_loss: 0.3098 - val_accuracy: 0.8889\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8390 - val_loss: 0.3543 - val_accuracy: 0.8889\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8379 - val_loss: 0.3674 - val_accuracy: 0.7778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: b01e5abaed7f89220d4f36d1d0f16cdc</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.8888888955116272</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 120</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMor04injwFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82a95bc6-98e2-405f-8d03-98d5063809b7"
      },
      "source": [
        "tuner.get_best_hyperparameters()[0].values\n",
        "                                                    \n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense_activation': 'sigmoid', 'learning_rate': 0.01, 'units': 440}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIvNVtEt-qWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m=tuner.get_best_models()[0]\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi6w1a4hns9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "outputId": "af66715b-de02-44eb-c00e-989bca421874"
      },
      "source": [
        "tuner.results_summary()\n"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Results in my_dggluir/helloworld</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e3437a02e9d5b988bd2e16fd638e34cb</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.9259259303410848</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: sigmoid</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 440</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: e976db2092b066d741c61f6b5a6de039</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.8888888955116272</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: tanh</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 448</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: b01e5abaed7f89220d4f36d1d0f16cdc</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.8888888955116272</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 120</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: f12c3f5635137afeb4e6291da29a18cd</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.814814825852712</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: relu</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 40</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 2b4a3fb951da6c4d649380f9297f28bc</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.7777777910232544</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-dense_activation: tanh</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-learning_rate: 0.0001</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-units: 272</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcobQRWAnw6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "dd8bd198-c1d2-49f4-cabe-eb737260e072"
      },
      "source": [
        "history=m.fit(y, x,epochs=20,validation_split=0.1, batch_size=5, verbose=1) \n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4201 - accuracy: 0.8290 - val_loss: 0.3501 - val_accuracy: 0.8556\n",
            "Epoch 2/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4248 - accuracy: 0.8152 - val_loss: 0.3406 - val_accuracy: 0.8444\n",
            "Epoch 3/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4162 - accuracy: 0.8190 - val_loss: 0.3676 - val_accuracy: 0.8667\n",
            "Epoch 4/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4143 - accuracy: 0.8290 - val_loss: 0.3547 - val_accuracy: 0.8667\n",
            "Epoch 5/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4072 - accuracy: 0.8290 - val_loss: 0.3550 - val_accuracy: 0.8556\n",
            "Epoch 6/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4115 - accuracy: 0.8302 - val_loss: 0.3322 - val_accuracy: 0.8444\n",
            "Epoch 7/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4147 - accuracy: 0.8377 - val_loss: 0.3462 - val_accuracy: 0.8556\n",
            "Epoch 8/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4108 - accuracy: 0.8265 - val_loss: 0.3333 - val_accuracy: 0.8778\n",
            "Epoch 9/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.3998 - accuracy: 0.8327 - val_loss: 0.3389 - val_accuracy: 0.8556\n",
            "Epoch 10/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4130 - accuracy: 0.8302 - val_loss: 0.3477 - val_accuracy: 0.8667\n",
            "Epoch 11/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4020 - accuracy: 0.8327 - val_loss: 0.3576 - val_accuracy: 0.8333\n",
            "Epoch 12/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4022 - accuracy: 0.8315 - val_loss: 0.3344 - val_accuracy: 0.8333\n",
            "Epoch 13/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4080 - accuracy: 0.8290 - val_loss: 0.3317 - val_accuracy: 0.8556\n",
            "Epoch 14/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4036 - accuracy: 0.8315 - val_loss: 0.3432 - val_accuracy: 0.8778\n",
            "Epoch 15/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4017 - accuracy: 0.8240 - val_loss: 0.3395 - val_accuracy: 0.8556\n",
            "Epoch 16/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4030 - accuracy: 0.8315 - val_loss: 0.3510 - val_accuracy: 0.8444\n",
            "Epoch 17/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.3993 - accuracy: 0.8377 - val_loss: 0.3353 - val_accuracy: 0.8667\n",
            "Epoch 18/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4169 - accuracy: 0.8202 - val_loss: 0.3432 - val_accuracy: 0.8444\n",
            "Epoch 19/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4058 - accuracy: 0.8340 - val_loss: 0.3205 - val_accuracy: 0.8667\n",
            "Epoch 20/20\n",
            "161/161 [==============================] - 1s 4ms/step - loss: 0.4088 - accuracy: 0.8252 - val_loss: 0.3498 - val_accuracy: 0.8778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZwKgmhv4D0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "bfd4e3c9-8bd7-4d3a-fa48-412707829b95"
      },
      "source": [
        "m.summary()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 440)               3520      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 440)               194040    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 441       \n",
            "=================================================================\n",
            "Total params: 198,001\n",
            "Trainable params: 198,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLjc6aeM4QkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 132,
      "outputs": []
    }
  ]
}